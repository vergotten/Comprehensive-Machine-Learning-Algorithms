{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyN0BnJJqR2v3EKjic2hlT9k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["The world is moving toward artificial intelligence. There are two main components of it: deep learning and machine learning. Without deep learning and machine learning, it is impossible to visualize artificial intelligence"],"metadata":{"id":"rQM3uX5-CW7K"}},{"cell_type":"markdown","source":["# Machine Learning and Deep Learning"],"metadata":{"id":"1s6Lv7-MC_n1"}},{"cell_type":"markdown","source":["Machine Learning and Deep Learning are both types of AI. Machine Learning uses algorithms to parse data, learn from that data, and make informed decisions based on what it has learned. Deep Learning, on the other hand, structures algorithms in layers to create an “artificial neural network” that can learn and make intelligent decisions on its own. Deep Learning is a subset of Machine Learning.\n","\n","Machine Learning provides excellent performances on a small/medium dataset, whereas Deep Learning provides excellent performance on a big dataset. Machine Learning works on a low-end machine, while Deep Learning requires a powerful machine, preferably with GPU. Machine Learning execution time ranges from few minutes to hours, whereas Deep Learning takes up to weeks.\n","\n","In short, Machine Learning is AI that can automatically adapt with minimal human interference. Deep learning is a subset of machine learning that uses artificial neural networks to mimic the learning process of the human brain."],"metadata":{"id":"tg4mVN30DAZm"}},{"cell_type":"markdown","source":["Machine Learning is a type of AI that uses algorithms to parse data, learn from that data, and make informed decisions based on what it has learned. Here are some examples of machine learning in action:\n","\n","* Linear regression\n","* Decision trees\n","* Random forest\n","* XGBoost\n","* Recommendation engines (e.g. Netflix)\n","* Sorting, tagging and categorizing photos (e.g. Yelp)\n","* Self-Driving Cars (e.g. Waymo)\n","* Education (e.g. Duolingo)\n","* Customer Lifetime Value (e.g. Asos)\n","* Patient Sickness Predictions (e.g. KenSci)\n","* Determining Credit Worthiness (e.g. Deserve)\n","* Targeted Emails (e.g. Optimail)\n","* Image recognition\n","* Speech recognition\n","* Virtual personal assistants\n","* Customer service reps\n","* Social media algorithms\n","* Fraud detection\n","* Streaming recommendations\n","* Traffic predictions\n","\n","These are just a few examples of how machine learning is being used in the real world to improve our daily lives and make informed decisions."],"metadata":{"id":"Gf2k2VUzCXfI"}},{"cell_type":"markdown","source":["Deep Learning is a subset of Machine Learning that uses artificial neural networks to mimic the learning process of the human brain. Here are some examples of deep learning in action:\n","\n","* Virtual assistants (e.g. Alexa, Cortana, Siri)\n","* Self-driving cars\n","* Chatbots\n","* Facial recognition\n","* Medical science\n","* Speech recognition\n","\n","These are just a few examples of how deep learning is being used in the real world to improve our daily lives and make informed decisions."],"metadata":{"id":"5Wb0BK6VED98"}},{"cell_type":"markdown","source":["AI is like a robot that can think and learn like a human. Machine Learning is when the robot learns by looking at lots of examples and figuring out what they have in common. Deep Learning is when the robot learns by looking at lots of examples, but it also tries to understand how the human brain works and learns in the same way. So, Machine Learning is like learning from a book, while Deep Learning is like learning from a book and also trying to think like a human."],"metadata":{"id":"b5kHMPngGHfO"}},{"cell_type":"markdown","source":["# PyTorch"],"metadata":{"id":"H2qnAWfaEzbB"}},{"cell_type":"markdown","source":["PyTorch is the most optimized high-performance tensor library for computation of deep learning tasks on GPUs (graphics processing units) and CPUs (central processing units). The main purpose of PyTorch is to enhance the performance of algorithms in large-scale computing environments. PyTorch is a library based on Python and the Torch tool provided by Facebook’s Artificial Intelligence Research group, which performs scientific computing.\n","\n","NumPy-based operations on a GPU are not efficient enough to process heavy computations. Static deep learning libraries are a bottleneck for bringing flexibility to computations and speed. From a practitioner’s point of view, PyTorch tensors are very similar to the N-dimensional arrays of a NumPy library based on Python. The PyTorch library provides bridge options for moving a NumPy array to a tensor array, and vice versa, in order to make the library flexible across different computing environments."],"metadata":{"id":"c0UYeRlCEyjj"}},{"cell_type":"markdown","source":["Although PyTorch provides a large collection of libraries and modules for computation, three modules are very prominent.\n","\n","* Autograd. This module provides functionality for automatic differentiation of tensors. A recorder class in the program remembers the operations and retrieves those operations with a trigger called backward to compute the gradients. This is immensely helpful in the implementation of neural network models.\n","\n","* Optim. This module provides optimization techniques that can be used to minimize the error function for a specific model. Currently, PyTorch supports various advanced optimization methods, which includes Adam, stochastic gradient descent (SGD), and more.\n","\n","* NN. NN stands for neural network model. Manually defining the functions, layers, and further computations using complete tensor operations is very difficult to remember and execute. We need functions that automate the layers, activation functions, loss functions, and optimization functions and provides a layer defined by the user so that manual intervention can be reduced. The NN module has a set of built-in functions that automates the manual process of running a tensor operation.\n"],"metadata":{"id":"PuJLEog4FBwx"}},{"cell_type":"markdown","source":["Every learning system requires three things: input data, processing, and an output layer."],"metadata":{"id":"hwxeY-kJGvrj"}},{"cell_type":"markdown","source":["# Types of learning"],"metadata":{"id":"Aa-DybJQHphw"}},{"cell_type":"markdown","source":["In a deep learning system, more than one layer of a learning algorithm is deployed. In machine learning, we think of supervised, unsupervised, semisupervised, and reinforcement learning systems.\n","\n","* A supervised machine-learning algorithm is one where the data is labeled with classes or tagged with outcomes. We show the machine the input data with corresponding tags or labels. The machine identifies the relationship with a function. Please note that this function connects the input to the labels or tags.\n","\n","* In unsupervised learning, we show the machine only the input data and ask the machine to group the inputs based on association, similarities or dissimilarities, and so forth.\n","\n","* In semisupervised learning, we show the machine input features and labeled data or tags; however we ask the machine to predict the untagged outcomes or labels.\n","\n","* In reinforcement learning, we introduce a reward and penalty mechanism, where every correct action is rewarded and every incorrect action is penalized.\n"],"metadata":{"id":"c6dfiEs8Hq1A"}},{"cell_type":"markdown","source":["In all of these examples of machine learning algorithms, we assume that the dataset is small, because getting massive amounts of tagged data is a challenge, and it takes a lot of time for machine learning algorithms to process large-scale matrix computations. Since machine learning algorithms are not scalable for massive datasets, we need deep learning algorithms."],"metadata":{"id":"r5aCox8RIVbm"}},{"cell_type":"markdown","source":["# Machine learning vs Deep learning task example"],"metadata":{"id":"pps2b2XHI56c"}},{"cell_type":"markdown","source":["Natural language is an important part of artificial intelligence. We need to develop systems that understand natural language and provide responses to the agent. Let’s take an example of machine translation, where a sentence in language 1 (French) can be converted to language 2 (English), and vice versa. To develop such a system, we need a large collection of English-French bilingual sentences. The corpus requirement is very large, as all the language nuances need to be covered by the model.\n","\n","After preprocessing and feature creation, you can observe hundreds of thousands of features that need to be computed to produce output. If we train a machine learning supervised model, it would take months to run and to produce output. To achieve scalability in this task, we need deep learning algorithms, such as a recurrent neural network. This is how the artificial intelligence is connected to deep learning and machine learning."],"metadata":{"id":"uUrDBrIrIeZb"}},{"cell_type":"markdown","source":["# Recipe 1-1. Using Tensors"],"metadata":{"id":"x2ixKrRfI3Yd"}},{"cell_type":"markdown","source":["The data structure used in PyTorch is graph based and tensor based, therefore, it is important to understand basic operations and defining tensors.\n"],"metadata":{"id":"JzW5ChdwJ7W7"}},{"cell_type":"markdown","source":["# Tensor operations"],"metadata":{"id":"4Slb9yDIKXE-"}},{"cell_type":"markdown","source":["The x object is a list. We can check whether an object in Python is a tensor object by using the following syntax.\n","\n","Typically, the is_tensor function checks and the is_storage function checks whether the object is stored as tensor object."],"metadata":{"id":"yiLcP5EhKdzz"}},{"cell_type":"markdown","source":["## is_tensor, is_storage function"],"metadata":{"id":"Ic5hClAML4Ut"}},{"cell_type":"code","source":["import torch\n","\n","x = [0,1,2,3,4,5,6,7,8,9]"],"metadata":{"id":"2ZHxpz0AKStG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.is_tensor(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKtreZ6eKyoI","executionInfo":{"status":"ok","timestamp":1694104753766,"user_tz":-180,"elapsed":29,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"0f29b805-1c7c-47bd-bcea-4218bf8816e3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":130}]},{"cell_type":"code","source":["torch.is_storage(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jHL0oJcZKyqQ","executionInfo":{"status":"ok","timestamp":1694104753766,"user_tz":-180,"elapsed":27,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"b2883b21-8b64-4a40-9017-e09116f958f2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":131}]},{"cell_type":"markdown","source":["Now, let’s create an object that contains random numbers from Torch, similar to NumPy library. We can check the tensor and storage type."],"metadata":{"id":"AV24LjezK6J5"}},{"cell_type":"code","source":["y = torch.randn(1,2,3,4,5)"],"metadata":{"id":"aawS6xDAK6pQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.is_tensor(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lg9sEl1kLAOS","executionInfo":{"status":"ok","timestamp":1694104753767,"user_tz":-180,"elapsed":21,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"b97089a3-f7a6-4324-f5d2-720d0403a7d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":133}]},{"cell_type":"code","source":["torch.is_storage(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dr_6dInJLAQm","executionInfo":{"status":"ok","timestamp":1694104753768,"user_tz":-180,"elapsed":18,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"ee7c425e-4bbb-47c0-e606-64b09f05e51d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":134}]},{"cell_type":"code","source":["a = torch.FloatStorage(6)\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRwywmb3LewV","executionInfo":{"status":"ok","timestamp":1694104753768,"user_tz":-180,"elapsed":15,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"478ec224-11ea-491d-8068-a0bfcbba008f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[" -1.2188698747195303e-05\n"," 3.3362113838645245e-41\n"," -1.1531737982295454e-05\n"," 3.3362113838645245e-41\n"," 4.484155085839415e-44\n"," 0.0\n","[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"]},"metadata":{},"execution_count":135}]},{"cell_type":"code","source":["torch.is_storage(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDQ-pJHyLs26","executionInfo":{"status":"ok","timestamp":1694104753768,"user_tz":-180,"elapsed":12,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"68e8373e-a65f-4c38-ba70-b815c7f958d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":136}]},{"cell_type":"code","source":["torch.numel(y)  # number of elements"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KiyBgx1TMAti","executionInfo":{"status":"ok","timestamp":1694104754191,"user_tz":-180,"elapsed":432,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"61b4716c-ab71-4b05-bc08-b4cf84722379"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["120"]},"metadata":{},"execution_count":137}]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWHdNp4_MGRp","executionInfo":{"status":"ok","timestamp":1694104754192,"user_tz":-180,"elapsed":67,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"dfae4f30-2718-47df-8e9f-9dc4fb9b3cec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[[ 0.0190,  0.0220,  1.1532, -0.3393,  0.1559],\n","           [ 0.8966, -0.2968,  1.5985, -0.0496, -1.2485],\n","           [-0.8509, -0.7690, -1.5606, -0.5309,  0.2178],\n","           [ 1.3232, -0.5660,  0.3566, -0.4535, -0.2971]],\n","\n","          [[-1.5380, -1.0248, -0.3781,  0.9257,  0.5158],\n","           [-1.0042,  0.9860,  1.1334,  0.8504,  1.0534],\n","           [ 0.3692,  0.0628, -0.6125,  0.7500, -0.7346],\n","           [ 0.4622,  1.1759,  0.2145,  0.5362,  0.1407]],\n","\n","          [[-2.3332,  1.5308,  0.2680,  0.4505, -0.2725],\n","           [-1.7399,  0.1299,  0.8519, -0.2829,  0.0731],\n","           [-1.3880, -0.2678, -0.1254, -1.5038, -0.3287],\n","           [ 0.7388, -1.4770, -1.2222, -0.2746, -0.3450]]],\n","\n","\n","         [[[-0.7162,  0.5781,  0.3805, -0.6780, -2.6740],\n","           [ 1.5984,  0.8021, -0.3511, -0.0670, -0.0534],\n","           [-0.8315,  0.9570,  1.2647, -0.2753, -0.1325],\n","           [ 0.1062,  0.0924, -1.1821,  0.2129,  0.1469]],\n","\n","          [[-0.6526,  0.7180, -0.4495, -0.7186,  0.6839],\n","           [-0.3458,  0.1858, -0.2632,  1.3226, -2.6796],\n","           [-0.1297, -0.6920,  1.1864,  0.2745, -0.3388],\n","           [-2.0155,  0.8078, -1.1421,  2.0506, -0.1523]],\n","\n","          [[-0.7381, -0.7189,  0.7937, -0.6129, -0.8981],\n","           [-0.9834,  0.7564,  0.3474,  0.2856, -0.0495],\n","           [ 0.6225,  0.1657, -1.3176,  1.2286,  0.7025],\n","           [-0.0170, -0.2830, -0.6446, -0.0199,  1.6222]]]]])"]},"metadata":{},"execution_count":138}]},{"cell_type":"markdown","source":["## torch.zeros"],"metadata":{"id":"VUAEn38HMk4d"}},{"cell_type":"markdown","source":["The following script is another example of creating zero values in a 2D tensor and counting the numerical elements in it."],"metadata":{"id":"lkNonAHGMugM"}},{"cell_type":"code","source":["torch.zeros(4,4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHMQS-BIMmYy","executionInfo":{"status":"ok","timestamp":1694104754192,"user_tz":-180,"elapsed":65,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"554d942d-adca-4acf-be03-eaf3c9634979"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0., 0.],\n","        [0., 0., 0., 0.],\n","        [0., 0., 0., 0.],\n","        [0., 0., 0., 0.]])"]},"metadata":{},"execution_count":139}]},{"cell_type":"code","source":["torch.numel(torch.zeros(4,4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1WkqhBCM0fe","executionInfo":{"status":"ok","timestamp":1694104754192,"user_tz":-180,"elapsed":61,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"1ef46d10-2776-4b63-cbbc-a777bd96eecd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{},"execution_count":140}]},{"cell_type":"markdown","source":["## torch.eye"],"metadata":{"id":"rDCrT_mMM6Ps"}},{"cell_type":"markdown","source":["Like NumPy operations, the eye function creates a diagonal matrix, of which the diagonal elements have ones, and off diagonal elements have zeros. The eye function can be manipulated by providing the shape option. The following example shows how to provide the shape parameter."],"metadata":{"id":"4_Jxt57GM7RS"}},{"cell_type":"code","source":["torch.eye(3,4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QfuoFyvLM_Zi","executionInfo":{"status":"ok","timestamp":1694104754192,"user_tz":-180,"elapsed":58,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"4c69c273-2f4a-4666-a154-2b8d064dfce2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0., 0.],\n","        [0., 1., 0., 0.],\n","        [0., 0., 1., 0.]])"]},"metadata":{},"execution_count":141}]},{"cell_type":"code","source":["torch.eye(5,4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3FcfV5mNojw","executionInfo":{"status":"ok","timestamp":1694104754193,"user_tz":-180,"elapsed":57,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"a50e078d-f6e0-44b3-d493-a7b230dbc788"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0., 0.],\n","        [0., 1., 0., 0.],\n","        [0., 0., 1., 0.],\n","        [0., 0., 0., 1.],\n","        [0., 0., 0., 0.]])"]},"metadata":{},"execution_count":142}]},{"cell_type":"markdown","source":["## torch.linspace"],"metadata":{"id":"TugtwakGN_UH"}},{"cell_type":"markdown","source":["Linear space and points between the linear space can be created using tensor operations. Let’s use an example of creating 25 points in a linear space starting from value 2 and ending with 10. Torch can read from a NumPy array format.\n"],"metadata":{"id":"rlaWaWZ1OBG0"}},{"cell_type":"code","source":["import numpy as np\n","\n","x1 = np.array(x)\n","x1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1xMceUYODt2","executionInfo":{"status":"ok","timestamp":1694104754193,"user_tz":-180,"elapsed":54,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"9f4a7b29-db9d-4df1-9ac8-bc1fc1421466"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{},"execution_count":143}]},{"cell_type":"code","source":["torch.from_numpy(x1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LIodfcrEOQ-p","executionInfo":{"status":"ok","timestamp":1694104754193,"user_tz":-180,"elapsed":52,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"cf7288d1-49be-4cf5-adbc-a7156b70520e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{},"execution_count":144}]},{"cell_type":"code","source":["torch.linspace(2, 10, steps=25)  # linear spacing"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Axkofy7XOeIq","executionInfo":{"status":"ok","timestamp":1694104754193,"user_tz":-180,"elapsed":49,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"5450df14-1234-4f4a-b2fd-626635a96da8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 2.0000,  2.3333,  2.6667,  3.0000,  3.3333,  3.6667,  4.0000,  4.3333,\n","         4.6667,  5.0000,  5.3333,  5.6667,  6.0000,  6.3333,  6.6667,  7.0000,\n","         7.3333,  7.6667,  8.0000,  8.3333,  8.6667,  9.0000,  9.3333,  9.6667,\n","        10.0000])"]},"metadata":{},"execution_count":145}]},{"cell_type":"markdown","source":["## torch.logspace"],"metadata":{"id":"VyYx9Of2OwK5"}},{"cell_type":"markdown","source":["The difference between linear and logarithmic spacing is in how the values are spaced along an axis. On a linear scale, the values are equally spaced, meaning that the difference between any two consecutive values is always the same. On a logarithmic scale, the values are spaced such that the ratio between any two consecutive values is always the same. This means that on a logarithmic scale, the values increase exponentially, with larger and larger gaps between consecutive values as you move along the axis.\n","\n","For example, consider a linear scale from 1 to 100 with 10 equally spaced values: 1, 11, 21, 31, 41, 51, 61, 71, 81, and 91. The difference between any two consecutive values is always 10. Now consider a logarithmic scale from 1 to 100 with 10 equally spaced values: 1, 10, 100, 1000, and so on. The ratio between any two consecutive values is always 10.\n","\n","Linear scales are useful when the data being plotted has a relatively small range of values or when the differences between the values are important. Logarithmic scales are useful when the data being plotted spans several orders of magnitude or when the ratios between the values are important."],"metadata":{"id":"vn00YVLsPl8l"}},{"cell_type":"code","source":["torch.logspace(start=-10, end=10, steps=25)  # logarithmic spacing"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pc9ajxWFOx2S","executionInfo":{"status":"ok","timestamp":1694104754194,"user_tz":-180,"elapsed":47,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"2803dbaa-2f7f-4a2b-d814-f3fc19de6732"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1.0000e-10, 6.8129e-10, 4.6416e-09, 3.1623e-08, 2.1544e-07, 1.4678e-06,\n","        1.0000e-05, 6.8129e-05, 4.6416e-04, 3.1623e-03, 2.1544e-02, 1.4678e-01,\n","        1.0000e+00, 6.8129e+00, 4.6416e+01, 3.1623e+02, 2.1544e+03, 1.4678e+04,\n","        1.0000e+05, 6.8129e+05, 4.6416e+06, 3.1623e+07, 2.1544e+08, 1.4678e+09,\n","        1.0000e+10])"]},"metadata":{},"execution_count":146}]},{"cell_type":"markdown","source":["## Normal and uniform distribution"],"metadata":{"id":"vKANfc9URXIx"}},{"cell_type":"markdown","source":["torch.randn and torch.rand are two functions in PyTorch that can be used to generate random numbers\n","\n","* torch.randn returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution). The shape of the tensor is defined by the variable argument size.\n","\n","* torch.rand returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1). The shape of the tensor is defined by the variable parameter sizes.\n","\n","In summary, the main difference between torch.randn and torch.rand is the distribution from which the random numbers are drawn. torch.randn generates random numbers from a normal distribution, while torch.rand generates random numbers from a uniform distribution."],"metadata":{"id":"c3kPODDwRa_s"}},{"cell_type":"markdown","source":["A normal distribution, also known as a Gaussian distribution, is a type of continuous probability distribution that is often used in statistics and other fields to represent real-valued random variables whose distributions are not known. The normal distribution is defined by two parameters: the mean, which specifies the center of the distribution, and the standard deviation, which specifies the spread of the distribution.\n","\n","The normal distribution has a bell-shaped curve, with the highest point at the mean and the curve falling off symmetrically on either side. The standard deviation determines how spread out the curve is. A larger standard deviation means that the curve is more spread out, while a smaller standard deviation means that the curve is more concentrated around the mean.\n","\n","The normal distribution is widely used in many fields because it often provides a good approximation to the distribution of many types of data. For example, it can be used to model measurement errors, stock returns, and many other types of data."],"metadata":{"id":"ECzJ8AhcR0it"}},{"cell_type":"markdown","source":["Random number generation is a common process in data science to generate or gather sample data points in a space to simulate structure in the data. Random numbers can be generated from a statistical distribution, any two values, or a predefined distribution. Like NumPy functions, the random number can be generated using the following example. Uniform distribution is defined as a distribution where each outcome has equal probability of happening; hence, the event probabilities are constant."],"metadata":{"id":"iFpZ30TNP6Ju"}},{"cell_type":"markdown","source":["In statistics, uniform distribution refers to a type of probability distribution in which all outcomes are equally likely. For example, when flipping a coin, the probability of getting either heads or tails is the same. This is an example of a discrete uniform distribution, where the outcomes are discrete and have the same probability.\n","\n","There are two types of uniform distributions: discrete and continuous. In a discrete uniform distribution, the outcomes are discrete and have the same probability. In a continuous uniform distribution, the outcomes are continuous and infinite.\n","\n","The uniform distribution can be visualized as a straight horizontal line. For example, for a coin flip returning heads or tails, both have a probability of 0.50 and would be depicted by a line from the y-axis at 0.501. The formula for a discrete uniform distribution is f(x) = 1 / (b - a + 1) for x = a, a + 1, ..., b, where a is the smallest value and b is the largest value."],"metadata":{"id":"8bNMdzBlQrD6"}},{"cell_type":"markdown","source":["### torch.rand"],"metadata":{"id":"duzWUHvfP47q"}},{"cell_type":"code","source":["# random numbers from a uniform distribution between the values 0 and 1\n","torch.rand(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0SVdcfAyP_Sh","executionInfo":{"status":"ok","timestamp":1694104754194,"user_tz":-180,"elapsed":44,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"1ee52e65-450d-4671-8ab0-f7e947f835f3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.2153, 0.2073, 0.4758, 0.0586, 0.8958, 0.5129, 0.7490, 0.2254, 0.4485,\n","        0.5658])"]},"metadata":{},"execution_count":147}]},{"cell_type":"markdown","source":["The following script shows how the random number from two values, 0 and 1, are selected. The result tensor can be reshaped to create a (4,5) matrix. The random numbers from a normal distribution with arithmetic mean 0 and standard deviation 1 can also be created, as follows.\n"],"metadata":{"id":"OuPpw2gtQxD6"}},{"cell_type":"code","source":["torch.rand(4,5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3t-_-R7WQyOr","executionInfo":{"status":"ok","timestamp":1694104754194,"user_tz":-180,"elapsed":42,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"739ad3c9-ed09-46c0-a985-3cd1fb5b8689"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3631, 0.9719, 0.2716, 0.6552, 0.1607],\n","        [0.4408, 0.3674, 0.7157, 0.8493, 0.6216],\n","        [0.4546, 0.3720, 0.8920, 0.3819, 0.8610],\n","        [0.2775, 0.9121, 0.9980, 0.8427, 0.7868]])"]},"metadata":{},"execution_count":148}]},{"cell_type":"markdown","source":["### torch.randn"],"metadata":{"id":"AKTw3HxwTced"}},{"cell_type":"code","source":["# random numbers from a normal distribution with mean=0 and standard deviation=1\n","torch.randn(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJw_Cdt2SVPA","executionInfo":{"status":"ok","timestamp":1694104754195,"user_tz":-180,"elapsed":40,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"7a2f392b-5a3b-4681-a750-732c4d11d12d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.3120,  0.0220,  0.8794, -0.2567, -0.7330,  0.8952,  0.6341, -0.7475,\n","        -0.3016, -1.1492])"]},"metadata":{},"execution_count":149}]},{"cell_type":"code","source":["torch.randn(4,5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OO1moqLMTGSz","executionInfo":{"status":"ok","timestamp":1694104754195,"user_tz":-180,"elapsed":38,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"18ae6418-d1df-409a-9d3d-3d19dc1a156a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 3.0292,  0.1858, -0.1704,  1.0270, -1.1049],\n","        [ 0.1970, -0.1435,  1.4660, -0.1042, -0.1376],\n","        [ 0.3774,  0.4664, -0.4066, -1.2096,  0.0365],\n","        [ 0.8257, -0.6476, -1.8021,  2.4911,  0.7702]])"]},"metadata":{},"execution_count":150}]},{"cell_type":"markdown","source":["### torch.normal"],"metadata":{"id":"rD4jXMO7Tg5y"}},{"cell_type":"markdown","source":["In PyTorch, you can generate random numbers from a normal distribution with a specified mean and standard deviation using the torch.normal function. This function takes two arguments: mean, which specifies the mean of the distribution, and std, which specifies the standard deviation of the distribution."],"metadata":{"id":"U4Nntb8fTMB7"}},{"cell_type":"code","source":["torch.normal(mean=5, std=10, size=(3,3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-QbH3mWTMhY","executionInfo":{"status":"ok","timestamp":1694104754195,"user_tz":-180,"elapsed":35,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"5e009550-62dc-4a5a-f94b-c1d291f0e932"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-3.8104, 31.0323,  3.5231],\n","        [15.8778, 16.8216, 10.7986],\n","        [-1.0500, -3.7557, 17.0463]])"]},"metadata":{},"execution_count":151}]},{"cell_type":"markdown","source":["## rand.perm"],"metadata":{"id":"67b5YurqT9w_"}},{"cell_type":"markdown","source":["To select random values from a range of values using random permutation requires defining the range first. This range can be created by using the arrange function. When using the arrange function, you must define the step size, which places all the values in an equal distance space. By default, the step size is 1.\n"],"metadata":{"id":"1v2p4wUyUBP9"}},{"cell_type":"code","source":["# selecting values from a range, this is called random permutation\n","torch.randperm(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MrSwQ_fUExz","executionInfo":{"status":"ok","timestamp":1694104754195,"user_tz":-180,"elapsed":31,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"5a431dbc-75b4-45a6-aba4-5e9d57c7940e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 5, 2, 7, 0, 6, 8, 4, 9, 3])"]},"metadata":{},"execution_count":152}]},{"cell_type":"code","source":["# usage of range function\n","torch.arange(10, 40, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmPdxt7cUWp9","executionInfo":{"status":"ok","timestamp":1694104754196,"user_tz":-180,"elapsed":29,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"8f95f4c0-013e-4f0b-ff0d-2324e042d465"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38])"]},"metadata":{},"execution_count":153}]},{"cell_type":"code","source":["torch.arange(10, 40)  # step size=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"caLPDA47Uf5D","executionInfo":{"status":"ok","timestamp":1694104754196,"user_tz":-180,"elapsed":27,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"99c6b7d2-c6c7-4f47-ca15-1aac139a82f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n","        28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39])"]},"metadata":{},"execution_count":154}]},{"cell_type":"markdown","source":["## torch.argmin, torch.argmax"],"metadata":{"id":"rxOhH_jjUw9I"}},{"cell_type":"markdown","source":["To find the minimum and maximum values in a 1D tensor, argmin and argmax can be used. The dimension needs to be mentioned if the input is a matrix in order to search minimum values along rows or columns."],"metadata":{"id":"BOkAAG88UzrC"}},{"cell_type":"code","source":["d = torch.randn(4,5)\n","d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RyWb06OdU2Qu","executionInfo":{"status":"ok","timestamp":1694104754196,"user_tz":-180,"elapsed":24,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"168d0a55-982a-47da-ca8d-dd85fc09da4e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.1206, -1.6680,  1.0685, -0.1831, -1.5684],\n","        [ 1.3443,  0.0372, -0.3598,  0.1032, -1.6268],\n","        [ 0.5729, -0.6995, -2.1433, -0.5419, -0.4255],\n","        [ 1.8125, -1.3636,  0.3067, -1.0327,  1.3824]])"]},"metadata":{},"execution_count":155}]},{"cell_type":"code","source":["d.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mojg2CaCXIWi","executionInfo":{"status":"ok","timestamp":1694104754196,"user_tz":-180,"elapsed":22,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"9d4670df-556a-4275-e02d-c25049f81bf5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 5])"]},"metadata":{},"execution_count":156}]},{"cell_type":"code","source":["torch.argmin(d, dim=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGBiTebhVkJe","executionInfo":{"status":"ok","timestamp":1694104754197,"user_tz":-180,"elapsed":20,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"65b10278-72bd-4929-db96-87daa17c1ec6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 4, 2, 1])"]},"metadata":{},"execution_count":157}]},{"cell_type":"code","source":["torch.argmax(d, dim=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxvbaQdEWAxE","executionInfo":{"status":"ok","timestamp":1694104754197,"user_tz":-180,"elapsed":17,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"a126eb03-dfaf-452d-b636-38d3e42040b3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2, 0, 0, 0])"]},"metadata":{},"execution_count":158}]},{"cell_type":"markdown","source":["If it is either a row or column, it is a single dimension and is called a 1D tensor. If the input is a matrix, in which rows and columns are present, it is called a 2D tensor. If it is more than two-dimensional, it is called a multidimensional tensor."],"metadata":{"id":"ewdIzjGNWOIZ"}},{"cell_type":"markdown","source":["## torch.cat"],"metadata":{"id":"28W2Q9sVWWNJ"}},{"cell_type":"markdown","source":["Now, let’s create a sample 2D tensor and perform indexing and concatenation by using the concat operation on the tensors."],"metadata":{"id":"JTzGC_UcWY1Z"}},{"cell_type":"code","source":["x = torch.rand(4,5)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7JQhk9cnWO6R","executionInfo":{"status":"ok","timestamp":1694104754197,"user_tz":-180,"elapsed":15,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"d95e2f16-e958-4b5a-9c18-2296025c38e0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642]])"]},"metadata":{},"execution_count":159}]},{"cell_type":"code","source":["# concatenate two tensors\n","\n","torch.cat((x,x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OcX-Qe15WhVf","executionInfo":{"status":"ok","timestamp":1694104754879,"user_tz":-180,"elapsed":694,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"b0ecb458-2de5-46e4-f7ac-cb8a6334c405"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642],\n","        [0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642]])"]},"metadata":{},"execution_count":160}]},{"cell_type":"markdown","source":["The sample x tensor can be used in 3D as well. Again, there are two different options to create three-dimensional tensors; the third dimension can be extended over rows or columns."],"metadata":{"id":"eKSlBPhiWwfS"}},{"cell_type":"code","source":["# concatenate n times based on array size, over column\n","\n","torch.cat((x,x,x),1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5tWp-pXWw2g","executionInfo":{"status":"ok","timestamp":1694104754879,"user_tz":-180,"elapsed":97,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"2adb1f63-60eb-418a-ac55-bee30e9fc3f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3532, 0.9624, 0.5881, 0.5701, 0.5513, 0.3532, 0.9624, 0.5881, 0.5701,\n","         0.5513, 0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773, 0.5326, 0.5210, 0.0655, 0.9826,\n","         0.9773, 0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151, 0.1558, 0.6236, 0.9133, 0.5968,\n","         0.7151, 0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642, 0.8724, 0.7122, 0.4096, 0.0844,\n","         0.2642, 0.8724, 0.7122, 0.4096, 0.0844, 0.2642]])"]},"metadata":{},"execution_count":161}]},{"cell_type":"code","source":["# concatenate n times based on array size, over rows\n","\n","torch.cat((x,x,x),0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8CE9aFeqXaE5","executionInfo":{"status":"ok","timestamp":1694104754879,"user_tz":-180,"elapsed":93,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"970d260e-e87b-4d77-fc10-cffcfc1ec531"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642],\n","        [0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642],\n","        [0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642]])"]},"metadata":{},"execution_count":162}]},{"cell_type":"markdown","source":["## torch.chunk"],"metadata":{"id":"ek1aF_wJXmzs"}},{"cell_type":"markdown","source":["A tensor can be split between multiple chunks. Those small chunks can be created along dim rows and dim columns. The following example shows a sample tensor of size (4,4). The chunk is created using the third argument in the function, as 0 or 1."],"metadata":{"id":"hJvsiF8lXoZJ"}},{"cell_type":"code","source":["a = torch.rand(4,4)\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzeCOBjhXqUM","executionInfo":{"status":"ok","timestamp":1694104754880,"user_tz":-180,"elapsed":91,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"d7eb73f2-1a8e-4c93-8ee9-435a4c0510db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2023, 0.5101, 0.1460, 0.8175],\n","        [0.5985, 0.2834, 0.2103, 0.6638],\n","        [0.3803, 0.5955, 0.5470, 0.5622],\n","        [0.4308, 0.4020, 0.3828, 0.6928]])\n"]}]},{"cell_type":"code","source":["torch.chunk(a,2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PVpkO4BYLNC","executionInfo":{"status":"ok","timestamp":1694104754880,"user_tz":-180,"elapsed":88,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"63d6e34e-3fee-4339-8d16-b4b4855c5bcd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.2023, 0.5101, 0.1460, 0.8175],\n","         [0.5985, 0.2834, 0.2103, 0.6638]]),\n"," tensor([[0.3803, 0.5955, 0.5470, 0.5622],\n","         [0.4308, 0.4020, 0.3828, 0.6928]]))"]},"metadata":{},"execution_count":164}]},{"cell_type":"code","source":["torch.chunk(a,2,0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yYi_mpgX6-A","executionInfo":{"status":"ok","timestamp":1694104754880,"user_tz":-180,"elapsed":85,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"db86c855-26ac-40fd-c964-f53e1999dee3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.2023, 0.5101, 0.1460, 0.8175],\n","         [0.5985, 0.2834, 0.2103, 0.6638]]),\n"," tensor([[0.3803, 0.5955, 0.5470, 0.5622],\n","         [0.4308, 0.4020, 0.3828, 0.6928]]))"]},"metadata":{},"execution_count":165}]},{"cell_type":"code","source":["torch.chunk(a,2,1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oFnZGPr4YA-n","executionInfo":{"status":"ok","timestamp":1694104754880,"user_tz":-180,"elapsed":82,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"4df776f1-4468-4c3a-85b3-fc33b53d2bb8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.2023, 0.5101],\n","         [0.5985, 0.2834],\n","         [0.3803, 0.5955],\n","         [0.4308, 0.4020]]),\n"," tensor([[0.1460, 0.8175],\n","         [0.2103, 0.6638],\n","         [0.5470, 0.5622],\n","         [0.3828, 0.6928]]))"]},"metadata":{},"execution_count":166}]},{"cell_type":"markdown","source":["## torch.gather"],"metadata":{"id":"67VDy0clYaKe"}},{"cell_type":"markdown","source":["The gather function collects elements from a tensor and places it in another tensor using an index argument. The index position is determined by the LongTensor function in PyTorch."],"metadata":{"id":"SPfZlzDJYb5d"}},{"cell_type":"code","source":["torch.Tensor([[11,12],[23,24]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhgSoBQ7Yefp","executionInfo":{"status":"ok","timestamp":1694104754881,"user_tz":-180,"elapsed":80,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"5cb8726f-fb55-4da7-b83d-c5d7a307b342"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[11., 12.],\n","        [23., 24.]])"]},"metadata":{},"execution_count":167}]},{"cell_type":"code","source":["torch.gather(torch.Tensor([[11,12],[23,24]]), 1,\n","             torch.LongTensor([[0,0],[1,0]]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWrjAlrlYmfT","executionInfo":{"status":"ok","timestamp":1694104754881,"user_tz":-180,"elapsed":78,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"24908726-27be-409b-d332-5ea3fd5a3061"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[11., 11.],\n","        [24., 23.]])"]},"metadata":{},"execution_count":168}]},{"cell_type":"code","source":["torch.gather(torch.Tensor([[11,12],[23,24]]), 0,\n","             torch.LongTensor([[0,0],[1,0]]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QjMf9OTIZAq7","executionInfo":{"status":"ok","timestamp":1694104754881,"user_tz":-180,"elapsed":75,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"5f5fcd9f-8b0e-4a17-c922-fe4e2aded20d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[11., 12.],\n","        [23., 12.]])"]},"metadata":{},"execution_count":169}]},{"cell_type":"code","source":["# the 1D tensor containing the indices to index\n","torch.LongTensor([[0,0],[1,0]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2KcKeykZgF7","executionInfo":{"status":"ok","timestamp":1694104754881,"user_tz":-180,"elapsed":72,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"301d49fe-ff93-48d3-99b5-a921a45e239a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 0],\n","        [1, 0]])"]},"metadata":{},"execution_count":170}]},{"cell_type":"markdown","source":["## torch.index_select"],"metadata":{"id":"fQhuEAuLZvY9"}},{"cell_type":"markdown","source":["The LongTensor function or the index select function can be used to fetch relevant values from a tensor. The following sample code shows two options: selection along rows and selection along columns. If the second argument is 0, it is for rows. If it is 1, then it is along the columns."],"metadata":{"id":"ivhZlQPlZyZD"}},{"cell_type":"code","source":["a = torch.randn(4,4)\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDZlNPMlZyyT","executionInfo":{"status":"ok","timestamp":1694104754882,"user_tz":-180,"elapsed":70,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"bb81c0ad-5048-44fe-8aeb-d30ba01208c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.6241,  0.9364,  0.7707, -0.1255],\n","        [-0.0446, -0.2705,  1.1501,  1.4566],\n","        [-0.0417,  0.7463,  0.3322, -0.1859],\n","        [-1.4301, -1.4317,  2.1155, -1.1853]])"]},"metadata":{},"execution_count":171}]},{"cell_type":"code","source":["indices = torch.LongTensor([0,2])"],"metadata":{"id":"ldOzfi3jZ37V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.index_select(a, 0, indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUr90DqCZ8qz","executionInfo":{"status":"ok","timestamp":1694104754882,"user_tz":-180,"elapsed":67,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"468dcae2-727d-4ed2-bc71-59e4fba84456"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.6241,  0.9364,  0.7707, -0.1255],\n","        [-0.0417,  0.7463,  0.3322, -0.1859]])"]},"metadata":{},"execution_count":173}]},{"cell_type":"code","source":["torch.index_select(a, 1, indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJNXWHYJaCr8","executionInfo":{"status":"ok","timestamp":1694104754883,"user_tz":-180,"elapsed":65,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"f9f28de4-d7ad-429e-94dc-a5883fe35f80"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.6241,  0.7707],\n","        [-0.0446,  1.1501],\n","        [-0.0417,  0.3322],\n","        [-1.4301,  2.1155]])"]},"metadata":{},"execution_count":174}]},{"cell_type":"markdown","source":["## torch.nonzero"],"metadata":{"id":"s6PfY02paJkg"}},{"cell_type":"markdown","source":["It is a common practice to check non-missing values in a tensor, the objective is to identify non-zero elements in a large tensor."],"metadata":{"id":"QikN3zVNaLy8"}},{"cell_type":"code","source":["# identify null input tensors using nonzero function\n","torch.nonzero(torch.tensor([10,00,23,0,0.0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Os_c2579aNWB","executionInfo":{"status":"ok","timestamp":1694104754883,"user_tz":-180,"elapsed":60,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"6817210e-b5fe-4fbd-ba1e-185c7dabc13a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0],\n","        [2]])"]},"metadata":{},"execution_count":175}]},{"cell_type":"code","source":["# identify null input tensors using nonzero function\n","torch.nonzero(torch.Tensor([10,00,23,0,0.0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKqtzN0UagMO","executionInfo":{"status":"ok","timestamp":1694104754883,"user_tz":-180,"elapsed":57,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"838a44b3-de97-4989-dad1-faa94b31e525"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0],\n","        [2]])"]},"metadata":{},"execution_count":176}]},{"cell_type":"markdown","source":["## torch.split"],"metadata":{"id":"f5s7Ipu6aj-C"}},{"cell_type":"markdown","source":["Restructuring the input tensors into smaller tensors not only fastens the calculation process, but also helps in distributed computing. The split function splits a long tensor into smaller tensors."],"metadata":{"id":"bIJBmb4kak84"}},{"cell_type":"code","source":["# splitting the tensor into small chunks\n","torch.split(torch.tensor([12,21,32,43,54,56,65,76]), 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RAmxxLIfaoOA","executionInfo":{"status":"ok","timestamp":1694104754883,"user_tz":-180,"elapsed":54,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"d11702cf-de3f-44f8-a2be-374a46ef9297"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([12, 21]), tensor([32, 43]), tensor([54, 56]), tensor([65, 76]))"]},"metadata":{},"execution_count":177}]},{"cell_type":"code","source":["# splitting the tensor into small chunks\n","torch.split(torch.tensor([12,21,32,43,54,56,65,76]), 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_dZ_XV4NbF8K","executionInfo":{"status":"ok","timestamp":1694104754884,"user_tz":-180,"elapsed":52,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"639a0164-a1be-433f-90be-d558db8f2c2c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([12, 21, 32]), tensor([43, 54, 56]), tensor([65, 76]))"]},"metadata":{},"execution_count":178}]},{"cell_type":"markdown","source":["## torch.transpose"],"metadata":{"id":"ESn2ub5rbKbI"}},{"cell_type":"markdown","source":["Now, let’s have a look at examples of how the input tensor can be resized given the computational difficulty. The transpose function is primarily used to reshape tensors. There are two ways of writing the transpose function: .t and .transpose."],"metadata":{"id":"a7rwUaYDbN6_"}},{"cell_type":"code","source":["# how to reshape the tensors along a new dimension"],"metadata":{"id":"5MsLLjD6bO3F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5njdpus-bUwR","executionInfo":{"status":"ok","timestamp":1694104754884,"user_tz":-180,"elapsed":49,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"b26767ff-00ec-41e3-852d-afd7f9d1e68a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642]])"]},"metadata":{},"execution_count":180}]},{"cell_type":"code","source":["x.t() # transpose is one option to change the shape of the tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ooGcPPQFbWJT","executionInfo":{"status":"ok","timestamp":1694104754884,"user_tz":-180,"elapsed":46,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"ac0ad281-1552-46a3-d700-f95f1b6eb63f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3532, 0.5326, 0.1558, 0.8724],\n","        [0.9624, 0.5210, 0.6236, 0.7122],\n","        [0.5881, 0.0655, 0.9133, 0.4096],\n","        [0.5701, 0.9826, 0.5968, 0.0844],\n","        [0.5513, 0.9773, 0.7151, 0.2642]])"]},"metadata":{},"execution_count":181}]},{"cell_type":"code","source":["x.transpose(1,0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ftJ9xum2beT-","executionInfo":{"status":"ok","timestamp":1694104754885,"user_tz":-180,"elapsed":44,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"7575e0f2-983a-4689-97f3-2b4f699306c5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3532, 0.5326, 0.1558, 0.8724],\n","        [0.9624, 0.5210, 0.6236, 0.7122],\n","        [0.5881, 0.0655, 0.9133, 0.4096],\n","        [0.5701, 0.9826, 0.5968, 0.0844],\n","        [0.5513, 0.9773, 0.7151, 0.2642]])"]},"metadata":{},"execution_count":182}]},{"cell_type":"markdown","source":["## torch.unbind"],"metadata":{"id":"cxUZVXWabktI"}},{"cell_type":"markdown","source":["The unbind function removes a dimension from a tensor. To remove the dimension row, the 0 value needs to be passed. To remove a column, the 1 value needs to be passed."],"metadata":{"id":"bTMUxSt3bmM3"}},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ry3jVoD2bnhh","executionInfo":{"status":"ok","timestamp":1694104754885,"user_tz":-180,"elapsed":42,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"0e411ee4-6529-4786-a843-121fea0cb84b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642]])"]},"metadata":{},"execution_count":183}]},{"cell_type":"code","source":["torch.unbind(x, 1) # dim=1, removing a column"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9tRbOXccCq3","executionInfo":{"status":"ok","timestamp":1694104754885,"user_tz":-180,"elapsed":39,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"23d715f6-8149-4aa0-b0df-f4d67726c2cf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.3532, 0.5326, 0.1558, 0.8724]),\n"," tensor([0.9624, 0.5210, 0.6236, 0.7122]),\n"," tensor([0.5881, 0.0655, 0.9133, 0.4096]),\n"," tensor([0.5701, 0.9826, 0.5968, 0.0844]),\n"," tensor([0.5513, 0.9773, 0.7151, 0.2642]))"]},"metadata":{},"execution_count":184}]},{"cell_type":"code","source":["torch.unbind(x) # dim=0, removing a row"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zsrlUAHPcQvG","executionInfo":{"status":"ok","timestamp":1694104754885,"user_tz":-180,"elapsed":36,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"392d9e5b-a2f4-4923-8f7e-a1f4a2c86e42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.3532, 0.9624, 0.5881, 0.5701, 0.5513]),\n"," tensor([0.5326, 0.5210, 0.0655, 0.9826, 0.9773]),\n"," tensor([0.1558, 0.6236, 0.9133, 0.5968, 0.7151]),\n"," tensor([0.8724, 0.7122, 0.4096, 0.0844, 0.2642]))"]},"metadata":{},"execution_count":185}]},{"cell_type":"markdown","source":["## torch.add, torch.mul"],"metadata":{"id":"MLIsIhJPce-2"}},{"cell_type":"markdown","source":["Mathematical functions are the backbone of implementing any algorithm in PyTorch; therefore, it is needed to go through functions that help perform arithmetic-based operations. A scalar is a single value, and a tensor 1D is a row, like NumPy. The scalar multiplication and addition with a 1D tensor are done using the add and mul functions."],"metadata":{"id":"fsQk3ZZRcf3i"}},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FwyBZhMchmg","executionInfo":{"status":"ok","timestamp":1694104754886,"user_tz":-180,"elapsed":34,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"bcb173da-7e8e-4051-8e3a-5c57f863fd42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642]])"]},"metadata":{},"execution_count":186}]},{"cell_type":"code","source":["torch.add(x,20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fumGtSUQckcP","executionInfo":{"status":"ok","timestamp":1694104754886,"user_tz":-180,"elapsed":31,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"c58b7437-0159-4854-e313-8e864f536401"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[20.3532, 20.9624, 20.5881, 20.5701, 20.5513],\n","        [20.5326, 20.5210, 20.0655, 20.9826, 20.9773],\n","        [20.1558, 20.6236, 20.9133, 20.5968, 20.7151],\n","        [20.8724, 20.7122, 20.4096, 20.0844, 20.2642]])"]},"metadata":{},"execution_count":187}]},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uzm-mRwKcogw","executionInfo":{"status":"ok","timestamp":1694104754886,"user_tz":-180,"elapsed":29,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"2a0101b2-4d1f-443e-bcf2-4d361745da15"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3532, 0.9624, 0.5881, 0.5701, 0.5513],\n","        [0.5326, 0.5210, 0.0655, 0.9826, 0.9773],\n","        [0.1558, 0.6236, 0.9133, 0.5968, 0.7151],\n","        [0.8724, 0.7122, 0.4096, 0.0844, 0.2642]])"]},"metadata":{},"execution_count":188}]},{"cell_type":"code","source":["torch.mul(x,2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o0fKXLXJcpgQ","executionInfo":{"status":"ok","timestamp":1694104754886,"user_tz":-180,"elapsed":26,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"e272d9b2-b9e8-4cc8-a1d8-a993c610f304"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.7065, 1.9247, 1.1762, 1.1402, 1.1025],\n","        [1.0652, 1.0421, 0.1310, 1.9653, 1.9547],\n","        [0.3116, 1.2473, 1.8266, 1.1936, 1.4301],\n","        [1.7448, 1.4245, 0.8192, 0.1687, 0.5284]])"]},"metadata":{},"execution_count":189}]},{"cell_type":"markdown","source":["Combined mathematical operations, such as expressing linear equations as tensor operations can be done using the following sample script. Here we express the outcome y object as a linear combination of beta values times the independent x object, plus the constant term."],"metadata":{"id":"P_jai30JczOn"}},{"cell_type":"code","source":["intercept = torch.randn(1)\n","intercept"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hMlElgQcztK","executionInfo":{"status":"ok","timestamp":1694104754887,"user_tz":-180,"elapsed":24,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"7e26a55e-20da-410b-9a59-865ea16cc7b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.3002])"]},"metadata":{},"execution_count":190}]},{"cell_type":"code","source":["x = torch.randn(2,2)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9VIZlFwFc65-","executionInfo":{"status":"ok","timestamp":1694104754887,"user_tz":-180,"elapsed":21,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"88cc94df-e118-4ef3-889c-1b50506d22c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.1125, -0.1628],\n","        [ 0.6744,  1.0753]])"]},"metadata":{},"execution_count":191}]},{"cell_type":"code","source":["beta = 0.7456\n","beta"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kmQpNPQc_y0","executionInfo":{"status":"ok","timestamp":1694104755274,"user_tz":-180,"elapsed":405,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"e53869ec-0204-4630-de19-1b2836d58166"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7456"]},"metadata":{},"execution_count":192}]},{"cell_type":"markdown","source":["Output = Constant + (beta * Independent)\n"],"metadata":{"id":"XT9oRtfMdFJT"}},{"cell_type":"code","source":["torch.mul(intercept, x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-eGufrRdHVY","executionInfo":{"status":"ok","timestamp":1694104755275,"user_tz":-180,"elapsed":65,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"3ac21f2f-bd2f-4994-e838-e40d32a4416d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.3340,  0.0489],\n","        [-0.2025, -0.3228]])"]},"metadata":{},"execution_count":193}]},{"cell_type":"code","source":["torch.mul(x, beta)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ganjb9oadQyp","executionInfo":{"status":"ok","timestamp":1694104755275,"user_tz":-180,"elapsed":61,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"3c6eb621-7f6d-46cf-a6cd-81ba1335edf6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.8295, -0.1214],\n","        [ 0.5028,  0.8017]])"]},"metadata":{},"execution_count":194}]},{"cell_type":"code","source":["## y = intercept + (beta * x)\n","torch.add(torch.mul(intercept,x), torch.mul(x,beta)) # tensor y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z6dnoOGOdXG4","executionInfo":{"status":"ok","timestamp":1694104755275,"user_tz":-180,"elapsed":58,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"3f531750-6832-47f1-8512-730929cf33b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.4955, -0.0725],\n","        [ 0.3004,  0.4789]])"]},"metadata":{},"execution_count":195}]},{"cell_type":"markdown","source":["## torch.ceil, torch.floor"],"metadata":{"id":"-rwlZ2gednaT"}},{"cell_type":"markdown","source":["Like NumPy operations, the tensor values must be rounded up by using either the ceiling or the flooring function, which is done using the following syntax."],"metadata":{"id":"hCnwCqUedukp"}},{"cell_type":"code","source":["# how to round up tensor values\n","torch.manual_seed(1234)\n","torch.randn(5,5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-szjiWuCdvFl","executionInfo":{"status":"ok","timestamp":1694104755275,"user_tz":-180,"elapsed":55,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"abbb9d32-d15f-47cc-f835-8fb8bece8d38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.1117, -0.4966,  0.1631, -0.8817,  0.0539],\n","        [ 0.6684, -0.0597, -0.4675, -0.2153, -0.7141],\n","        [-1.0831, -0.5547,  0.9717, -0.5150,  1.4255],\n","        [ 0.7987, -1.4949,  1.4778, -0.1696, -0.9919],\n","        [-1.4569,  0.2563, -0.4030,  0.4195,  0.9380]])"]},"metadata":{},"execution_count":196}]},{"cell_type":"code","source":["torch.manual_seed(1234)\n","torch.ceil(torch.randn(5,5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sv846-ZPd9AD","executionInfo":{"status":"ok","timestamp":1694104755275,"user_tz":-180,"elapsed":53,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"44bc9de7-f63f-4a31-d878-7411d63920d8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0., -0.,  1., -0.,  1.],\n","        [ 1., -0., -0., -0., -0.],\n","        [-1., -0.,  1., -0.,  2.],\n","        [ 1., -1.,  2., -0., -0.],\n","        [-1.,  1., -0.,  1.,  1.]])"]},"metadata":{},"execution_count":197}]},{"cell_type":"code","source":["torch.manual_seed(1234)\n","torch.floor(torch.randn(5,5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRhEzw4WeHld","executionInfo":{"status":"ok","timestamp":1694104755276,"user_tz":-180,"elapsed":51,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"f80df2a1-499c-4ab3-cec0-8675622cb646"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1., -1.,  0., -1.,  0.],\n","        [ 0., -1., -1., -1., -1.],\n","        [-2., -1.,  0., -1.,  1.],\n","        [ 0., -2.,  1., -1., -1.],\n","        [-2.,  0., -1.,  0.,  0.]])"]},"metadata":{},"execution_count":198}]},{"cell_type":"markdown","source":["## torch.clamp"],"metadata":{"id":"WebCWgDbeOwi"}},{"cell_type":"markdown","source":["Limiting the values of any tensor within a certain range can be done using the minimum and maximum argument and using the clamp function. The same function can apply minimum and maximum in parallel or any one of them to any tensor, be it 1D or 2D; 1D is the far simpler version. The following example shows the implementation in  a 2D scenario."],"metadata":{"id":"wcTYl4Z9ePr5"}},{"cell_type":"code","source":["torch.manual_seed(1234)\n","torch.clamp(torch.floor(torch.randn(5,5)), min=-0.3, max=0.4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgVekgzjeRWy","executionInfo":{"status":"ok","timestamp":1694104755276,"user_tz":-180,"elapsed":48,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"cd1bef89-6dd4-40e7-c55f-b27c67e63bc3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3000, -0.3000,  0.0000, -0.3000,  0.0000],\n","        [ 0.0000, -0.3000, -0.3000, -0.3000, -0.3000],\n","        [-0.3000, -0.3000,  0.0000, -0.3000,  0.4000],\n","        [ 0.0000, -0.3000,  0.4000, -0.3000, -0.3000],\n","        [-0.3000,  0.0000, -0.3000,  0.0000,  0.0000]])"]},"metadata":{},"execution_count":199}]},{"cell_type":"code","source":["# truncate with only lower limit\n","torch.manual_seed(1234)\n","torch.clamp(torch.floor(torch.randn(5,5)), min=-0.3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqxIHD-7elep","executionInfo":{"status":"ok","timestamp":1694104755276,"user_tz":-180,"elapsed":46,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"d2d54ecc-6ffd-41d7-8bc2-8efe8d70d18e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3000, -0.3000,  0.0000, -0.3000,  0.0000],\n","        [ 0.0000, -0.3000, -0.3000, -0.3000, -0.3000],\n","        [-0.3000, -0.3000,  0.0000, -0.3000,  1.0000],\n","        [ 0.0000, -0.3000,  1.0000, -0.3000, -0.3000],\n","        [-0.3000,  0.0000, -0.3000,  0.0000,  0.0000]])"]},"metadata":{},"execution_count":200}]},{"cell_type":"code","source":["# truncate with only upper limit\n","torch.manual_seed(1234)\n","torch.clamp(torch.floor(torch.randn(5,5)), max=0.3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HkOc2rRNezRo","executionInfo":{"status":"ok","timestamp":1694104755276,"user_tz":-180,"elapsed":43,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"75d6abf1-e24d-4d27-d68d-3cd8a3e9516f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.0000, -1.0000,  0.0000, -1.0000,  0.0000],\n","        [ 0.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","        [-2.0000, -1.0000,  0.0000, -1.0000,  0.3000],\n","        [ 0.0000, -2.0000,  0.3000, -1.0000, -1.0000],\n","        [-2.0000,  0.0000, -1.0000,  0.0000,  0.0000]])"]},"metadata":{},"execution_count":201}]},{"cell_type":"markdown","source":["## torch.exp"],"metadata":{"id":"6NXMhcaifAWc"}},{"cell_type":"code","source":["# compute the exponential of a tensor\n","torch.exp(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LePnvSi2fBWL","executionInfo":{"status":"ok","timestamp":1694104755277,"user_tz":-180,"elapsed":41,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"8d90c444-2790-4eea-84eb-1dfafa17e7ab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3287, 0.8497],\n","        [1.9629, 2.9308]])"]},"metadata":{},"execution_count":202}]},{"cell_type":"code","source":["np.exp(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLmvx-lifHe_","executionInfo":{"status":"ok","timestamp":1694104755277,"user_tz":-180,"elapsed":39,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"f8114531-3378-4ccc-b667-bb657dc49c99"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3287, 0.8497],\n","        [1.9629, 2.9308]])"]},"metadata":{},"execution_count":203}]},{"cell_type":"code","source":["# how to get the fractional portion of each tensor\n","torch.add(x,10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAabFfwSfLIa","executionInfo":{"status":"ok","timestamp":1694104755277,"user_tz":-180,"elapsed":36,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"1e137140-aa8d-4a3a-8fcb-a1c0edc823f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 8.8875,  9.8372],\n","        [10.6744, 11.0753]])"]},"metadata":{},"execution_count":204}]},{"cell_type":"code","source":["torch.frac(torch.add(x,10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mnYnechrfZlb","executionInfo":{"status":"ok","timestamp":1694104755277,"user_tz":-180,"elapsed":34,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"3448913b-5288-407e-cdcf-d7ccbcbacfc4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8875, 0.8372],\n","        [0.6744, 0.0753]])"]},"metadata":{},"execution_count":205}]},{"cell_type":"markdown","source":["## torch.log, torch.pow"],"metadata":{"id":"5HQXRBjjfmi8"}},{"cell_type":"markdown","source":["The following syntax explains the logarithmic values in a tensor. The values with a negative sign are converted to nan. The power function computes the exponential of any value in a tensor."],"metadata":{"id":"PvTEJrrFfpeU"}},{"cell_type":"code","source":["# compute the log of the values in a tensor"],"metadata":{"id":"Uzr1jbhSftWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kL0bBIHSfz8j","executionInfo":{"status":"ok","timestamp":1694104755278,"user_tz":-180,"elapsed":32,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"b5490425-e7bd-4458-8fb8-465df3df4501"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.1125, -0.1628],\n","        [ 0.6744,  1.0753]])"]},"metadata":{},"execution_count":207}]},{"cell_type":"code","source":["torch.log(x) # log of negatives are nan"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQR_qtPKf08p","executionInfo":{"status":"ok","timestamp":1694104755278,"user_tz":-180,"elapsed":29,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"a80f15c9-e61d-41fb-d42d-35681d4a4938"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[    nan,     nan],\n","        [-0.3939,  0.0726]])"]},"metadata":{},"execution_count":208}]},{"cell_type":"code","source":["# to rectify the negative values do a power transformation\n","torch.pow(x,2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F6vwQyj0gBsx","executionInfo":{"status":"ok","timestamp":1694104755278,"user_tz":-180,"elapsed":27,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"310ef4b6-2c41-4df3-fad8-e530e4a8f6b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.2376, 0.0265],\n","        [0.4548, 1.1562]])"]},"metadata":{},"execution_count":209}]},{"cell_type":"markdown","source":["## torch.sigmoid, torch.sqrt"],"metadata":{"id":"asbiiBLSgOVs"}},{"cell_type":"markdown","source":["To compute the transformation functions (i.e., sigmoid, hyperbolic tangent, radial basis function, and so forth, which are the most commonly used transfer functions in deep learning), you must construct the tensors. The following sample script shows how to create a sigmoid function and apply it on a tensor."],"metadata":{"id":"bmlFDwgWgQnR"}},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPcCGRKygSVn","executionInfo":{"status":"ok","timestamp":1694104755278,"user_tz":-180,"elapsed":25,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"a0b83fbe-9e50-4f27-d4da-e35a7e617da5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.1125, -0.1628],\n","        [ 0.6744,  1.0753]])"]},"metadata":{},"execution_count":210}]},{"cell_type":"code","source":["# how to compute the sigmoid of the input tensor\n","\n","torch.sigmoid(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ut5-MzZgXiU","executionInfo":{"status":"ok","timestamp":1694104755279,"user_tz":-180,"elapsed":23,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"677b2a58-6708-4e81-bbb2-b8927fae1fac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2474, 0.4594],\n","        [0.6625, 0.7456]])"]},"metadata":{},"execution_count":211}]},{"cell_type":"code","source":["# finding the square root of the values\n","\n","torch.sqrt(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-q3ij86ggIo","executionInfo":{"status":"ok","timestamp":1694104755279,"user_tz":-180,"elapsed":21,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"b0947732-c357-4bd1-debd-2b19d67f2808"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[   nan,    nan],\n","        [0.8212, 1.0370]])"]},"metadata":{},"execution_count":212}]},{"cell_type":"markdown","source":["# Conclusion"],"metadata":{"id":"rtMXHVx4gqoy"}},{"cell_type":"markdown","source":["This chapter is a refresher for people who have prior experience in PyTorch and Python. It is a basic building block for people who are new to the PyTorch framework. Before starting the advanced topics, it is important to become familiar with the terminology and basic syntaxes. The next chapter is on using PyTorch to implement probabilistic models, which includes the creation of random variables, the application of statistical distributions, and making statistical inferences."],"metadata":{"id":"L_hijAXqgsyz"}}]}
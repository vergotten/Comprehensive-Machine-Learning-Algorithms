## Supervised Learning

Supervised Learning is a type of machine learning where models are trained using labeled data. The model makes predictions based on this data and the accuracy of the predictions is improved over time.

### Regression

Regression: It’s a statistical method used to understand the relationship between dependent and independent variables. It’s commonly used to make projections, such as for sales revenue for a given business.


### Classification

Classification, on the other hand, is a process in machine learning where we categorize data into a given number of classes. The main goal of a classification problem is to identify the category/class to which a new data will fall under. Classification can be performed on both structured or unstructured data. Classification is a two-step process, learning step and prediction step. In the learning step, the model is developed based on given training data. In the prediction step, the model is used to predict the response for given data.

#### K-Nearest Neighbors (KNN)

K-Nearest Neighbors (KNN): This is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all computation is deferred until function evaluation.

#### Support Vector Machines (SVM)

Support Vector Machines (SVM): SVMs are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis.

#### Naive Bayes

Naive Bayes: This is a simple technique for constructing classifiers: models that assign class labels to problem instances, represented as vectors of feature values, where the class labels are drawn from some finite set.

#### Decision Trees

Decision Trees: A decision tree is a decision support hierarchical model that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility.

### Ensemble Methods

Ensemble Methods: These are techniques that aim at improving the accuracy of results in models by combining multiple models instead of using a single model.

#### Random Forest

Random Forest: Random forest is a commonly-used machine learning algorithm that combines the output of multiple decision trees to reach a single result.

#### AdaBoost

AdaBoost: AdaBoost is a type of algorithm that uses an ensemble learning approach to weight various inputs. It was designed by Yoav Freund and Robert Schapire in the early 21st century.

#### Gradient Boosting

Gradient Boosting: Gradient boosting is a machine learning technique for regression and classification problems that produces a prediction model in the form of an ensemble of weak prediction models.

#### XGBoost

XGBoost is an implementation of gradient-boosted decision trees designed for speed and performance that is dominantly competitive in machine learning.

#### LightGBM

#### CatBoost

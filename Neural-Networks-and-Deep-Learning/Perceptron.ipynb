{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOF7tfHzi0pJ3vOVynb2sxB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Perceptron\n","\n","Perceptron is a type of artificial neural network invented in 1957 by Frank Rosenblatt. It can be seen as the simplest kind of feedforward neural network: a linear classifier.\n","\n","## How it Works\n","\n","A perceptron works by using a binary linear classifier to make predictions. It takes a vector of input features and multiplies each feature by a corresponding weight, sums up the results, and applies a step function to the sum to get the output.\n","\n","The perceptron starts by initializing the weights randomly. Then, for each instance in the training set, it makes a prediction. If the prediction is incorrect, it updates the weights in the direction that would have made the prediction correct.\n","\n","## Use Cases\n","\n","Perceptrons have a wide range of applications, including:\n","\n","- **Binary Classification Problems**: Perceptrons can be used for binary classification tasks, such as spam detection or tumor detection.\n","\n","- **Linearly Separable Data**: Perceptrons work best when the data is linearly separable, i.e., when a straight line can separate the positive and negative examples.\n","\n","- **Large-Scale Learning**: Due to their simplicity, perceptrons can be used for large-scale machine learning tasks.\n","\n","## Limitations\n","\n","Despite their advantages, Perceptrons also have some limitations:\n","\n","- **Linearly Separable Data**: Perceptrons can only solve problems if the data is linearly separable. They cannot solve problems where the data is not linearly separable, such as the XOR problem.\n","\n","- **Convergence**: If the data is not linearly separable, the perceptron learning algorithm will never converge. It will keep updating the weights indefinitely.\n","\n","- **Interpretability**: Like other machine learning models, perceptrons can be seen as \"black boxes\" and can be difficult to interpret. This can make it challenging to understand why a particular prediction was made."],"metadata":{"id":"nKfNk0aU8cLy"}},{"cell_type":"markdown","source":["# Перцептрон\n","\n","Перцептрон - это тип искусственной нейронной сети, изобретенный в 1957 году Фрэнком Розенблаттом. Это можно рассматривать как самый простой вид прямого распространения нейронной сети: линейный классификатор.\n","\n","## Как это работает\n","\n","Перцептрон работает, используя бинарный линейный классификатор для прогнозирования. Он принимает вектор входных признаков и умножает каждый признак на соответствующий вес, суммирует результаты и применяет ступенчатую функцию к сумме, чтобы получить выход.\n","\n","Перцептрон начинает с инициализации весов случайным образом. Затем, для каждого экземпляра в обучающем наборе, он делает прогноз. Если прогноз неверен, он обновляет веса в направлении, которое сделало бы прогноз верным.\n","\n","## Варианты использования\n","\n","У перцептронов есть широкий спектр применений, включая:\n","\n","- **Задачи бинарной классификации**: Перцептроны могут использоваться для задач бинарной классификации, таких как обнаружение спама или обнаружение опухолей.\n","\n","- **Линейно разделимые данные**: Перцептроны лучше всего работают, когда данные линейно разделимы, то есть когда прямая линия может разделить положительные и отрицательные примеры.\n","\n","- **Обучение в большом масштабе**: Из-за их простоты перцептроны могут использоваться для задач машинного обучения в большом масштабе.\n","\n","## Ограничения\n","\n","Несмотря на их преимущества, у перцептронов также есть некоторые ограничения:\n","\n","- **Линейно разделимые данные**: Перцептроны могут решать проблемы только в том случае, если данные линейно разделимы. Они не могут решать проблемы, когда данные не являются линейно разделимыми, например, проблему XOR.\n","\n","- **Сходимость**: Если данные не являются линейно разделимыми, алгоритм обучения перцептрона никогда не сойдется. Он будет продолжать обновлять веса бесконечно.\n","\n","- **Интерпретируемость**: Как и другие модели машинного обучения, перцептроны могут рассматриваться как \"черные ящики\" и могут быть сложными для интерпретации. Это может затруднить понимание причин, по которым был сделан определенный прогноз."],"metadata":{"id":"VSWCpg9h8cOH"}},{"cell_type":"code","source":["import torch\n","import os\n","\n","class Perceptron:\n","    \"\"\"\n","    A Perceptron is a type of artificial neural network invented in 1957 by Frank Rosenblatt.\n","    It can be seen as the simplest kind of feedforward neural network: a linear classifier.\n","    \"\"\"\n","\n","    def __init__(self, input_dim, learning_rate=0.01):\n","        \"\"\"\n","        Constructs all the necessary attributes for the Perceptron object.\n","\n","        Parameters:\n","            input_dim (int): The number of dimensions of the input data\n","            learning_rate (float): The learning rate for updating the weights\n","        \"\"\"\n","        self.weights = torch.randn(input_dim, requires_grad=True)\n","        self.bias = torch.randn(1, requires_grad=True)\n","        self.learning_rate = learning_rate\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the Perceptron.\n","\n","        Parameters:\n","            x (torch.Tensor): The input data\n","\n","        Returns:\n","            output (torch.Tensor): The output of the Perceptron\n","        \"\"\"\n","        output = torch.matmul(x, self.weights) + self.bias\n","        return output\n","\n","    def backward(self, output, y):\n","        \"\"\"\n","        Backward pass of the Perceptron.\n","\n","        Parameters:\n","            output (torch.Tensor): The output of the Perceptron\n","            y (torch.Tensor): The true labels\n","        \"\"\"\n","        loss = torch.mean((output - y)**2)\n","        loss.backward()\n","\n","    def update_weights(self):\n","        \"\"\"\n","        Updates the weights and bias of the Perceptron using the gradients computed in the backward pass.\n","        \"\"\"\n","        with torch.no_grad():\n","            self.weights -= self.learning_rate * self.weights.grad\n","            self.bias -= self.learning_rate * self.bias.grad\n","\n","        self.weights.grad.zero_()\n","        self.bias.grad.zero_()\n","\n","    def train(self, X, y, epochs):\n","        \"\"\"\n","        Trains the Perceptron on the given data for a certain number of epochs.\n","\n","        Parameters:\n","            X (torch.Tensor): The input data\n","            y (torch.Tensor): The true labels\n","            epochs (int): The number of times to iterate over the entire dataset\n","        \"\"\"\n","        for epoch in range(epochs):\n","            output = self.forward(X)\n","            self.backward(output, y)\n","            self.update_weights()\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Makes predictions on the given data.\n","\n","        Parameters:\n","            X (torch.Tensor): The input data\n","\n","        Returns:\n","            predictions (torch.Tensor): The predictions of the Perceptron\n","        \"\"\"\n","        output = self.forward(X)\n","        predictions = torch.where(output >= 0, 1, 0)\n","        return predictions\n","\n","    def save_model(self, file_path):\n","        \"\"\"\n","        Saves the current state of the model (weights and bias) to a file.\n","\n","        Parameters:\n","            file_path (str): The path where the model should be saved\n","        \"\"\"\n","        torch.save({\n","            'weights': self.weights,\n","            'bias': self.bias\n","        }, file_path)\n","\n","    def load_model(self, file_path):\n","        \"\"\"\n","        Loads the state of the model (weights and bias) from a file.\n","\n","        Parameters:\n","            file_path (str): The path from where the model should be loaded\n","        \"\"\"\n","        if os.path.isfile(file_path):\n","            checkpoint = torch.load(file_path)\n","            self.weights = checkpoint['weights']\n","            self.bias = checkpoint['bias']\n","        else:\n","            print(\"Invalid file path. No model was loaded.\")\n","\n","# Create random data\n","X = torch.randn(100, 10)\n","y = torch.randint(0, 2, (100,))\n","\n","# Create and train the Perceptron\n","perceptron = Perceptron(input_dim=10, learning_rate=0.01)\n","perceptron.train(X, y, epochs=100)\n","\n","# Make predictions\n","predictions = perceptron.predict(X)\n","print(predictions)\n","\n","# Save the model\n","perceptron.save_model('perceptron_model.pt')\n","\n","# Load the model\n","perceptron.load_model('perceptron_model.pt')\n"],"metadata":{"id":"yXdmvaNU8cVL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701898107279,"user_tz":-180,"elapsed":358,"user":{"displayName":"Maxim Sorokin","userId":"04915505168425669858"}},"outputId":"92c53e37-eb9e-49a9-c7f0-5a501e3b6824"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n","        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n","        1, 1, 1, 1])\n"]}]},{"cell_type":"markdown","source":["This code creates a Perceptron class with methods for the forward pass, backward pass, updating the weights, training the model, making predictions, saving the model, and loading the model. The `forward` method computes the output of the Perceptron, the `backward` method computes the gradients, the `update_weights` method updates the weights and bias using the gradients, the `train` method trains the model on the given data for a certain number of epochs, the `predict` method makes predictions on the given data, the `save_model` method saves the current state of the model to a file, and the `load_model` method loads the state of the model from a file. The `learning_rate` parameter can be adjusted to control the learning rate for updating the weights."],"metadata":{"id":"PMQw7K1hCNwF"}},{"cell_type":"markdown","source":["Этот код создаёт класс Perceptron с методами для прямого прохода, обратного прохода, обновления весов, обучения модели, прогнозирования, сохранения модели и загрузки модели. Метод `forward` вычисляет выход Perceptron, метод `backward` вычисляет градиенты, метод `update_weights` обновляет веса и смещение с использованием вычисленных градиентов, метод `train` обучает модель на заданных данных в течение определенного числа эпох, метод `predict` делает прогнозы на заданных данных, метод `save_model` сохраняет текущее состояние модели в файл, а метод `load_model` загружает состояние модели из файла. Параметр `learning_rate` можно настроить для контроля скорости обучения при обновлении весов."],"metadata":{"id":"EcWWTLyPCNyv"}}]}